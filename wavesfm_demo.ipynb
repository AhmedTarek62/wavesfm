{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# WavesFM end-to-end finetuning demo\n",
        "\n",
        "This notebook walks through:\n",
        "1. Clone the WavesFM repo\n",
        "2. Install dependencies\n",
        "3. Download raw data\n",
        "4. Preprocess to a .h5 cache\n",
        "5. Download a pretrained checkpoint\n",
        "6. Finetune on a task\n",
        "7. Evaluate with a confusion matrix (classification) or an error density plot (positioning)\n",
        "\n",
        "You can switch tasks using the config cell below.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0. Configuration\n",
        "Adjust the task and knobs below. For positioning tasks, the evaluation cell will switch to error density plots automatically.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# ---- task + paths ----\n",
        "TASK = \"deepmimo-los\"  # examples: \"deepmimo-los\", \"deepmimo-beam\", \"rml\", \"pos\"\n",
        "DATA_ROOT = Path(\"data\")\n",
        "RAW_ROOT = DATA_ROOT / \"raw\"\n",
        "CACHE_ROOT = DATA_ROOT / \"cache\"\n",
        "OUTPUT_DIR = Path(\"runs/demo\")\n",
        "CHECKPOINT_DIR = Path(\"checkpoints\")\n",
        "\n",
        "# ---- pipeline toggles ----\n",
        "DOWNLOAD_RAW = True\n",
        "PREPROCESS = True\n",
        "DOWNLOAD_PRETRAINED = True\n",
        "RUN_TRAINING = True\n",
        "\n",
        "# ---- dataset-specific knobs ----\n",
        "DEEP_MIMO_SCENARIO_IDXS = \"0\"  # small subset for a quick run\n",
        "DEEP_MIMO_N_BEAMS = 16         # used for deepmimo-beam\n",
        "POS_SCENE = \"outdoor\"          # \"indoor\" or \"outdoor\"\n",
        "RML_VERSION = \"2022\"\n",
        "RML_DATA_FILE = RAW_ROOT / \"RML22.01A\"  # update if needed\n",
        "\n",
        "# ---- training knobs ----\n",
        "MODEL_NAME = \"vit_multi_small\"\n",
        "EPOCHS = 1\n",
        "BATCH_SIZE = 16\n",
        "VAL_SPLIT = 0.2\n",
        "NUM_WORKERS = 4\n",
        "USE_STRATIFIED_SPLIT = True\n",
        "FULL_FINETUNE = False  # set True to train all weights (adds --sl-baseline)\n",
        "\n",
        "\n",
        "def resolve_cache_path():\n",
        "    if TASK.startswith(\"deepmimo\"):\n",
        "        return CACHE_ROOT / \"deepmimo.h5\"\n",
        "    if TASK == \"pos\":\n",
        "        return CACHE_ROOT / f\"pos_{POS_SCENE}.h5\"\n",
        "    if TASK == \"rml\":\n",
        "        return CACHE_ROOT / f\"rml{RML_VERSION}.h5\"\n",
        "    return CACHE_ROOT / f\"{TASK}.h5\"\n",
        "\n",
        "\n",
        "CACHE_PATH = resolve_cache_path()\n",
        "print(\"Task:\", TASK)\n",
        "print(\"Cache path:\", CACHE_PATH)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Clone the repo\n",
        "If you already opened this notebook from a local clone, this will reuse it.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import sys\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "\n",
        "REPO_URL = \"https://github.com/AhmedTarek62/wavesfm.git\"\n",
        "REPO_DIR = Path.cwd()\n",
        "\n",
        "if not (REPO_DIR / \"main_finetune.py\").exists():\n",
        "    REPO_DIR = Path.cwd() / \"wavesfm\"\n",
        "    if not REPO_DIR.exists():\n",
        "        subprocess.run([\"git\", \"clone\", REPO_URL, str(REPO_DIR)], check=True)\n",
        "\n",
        "if str(REPO_DIR) not in sys.path:\n",
        "    sys.path.insert(0, str(REPO_DIR))\n",
        "\n",
        "print(\"Using repo:\", REPO_DIR)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Install dependencies\n",
        "Install the pinned dependencies. If you have a GPU, replace the torch install line with the CUDA build from pytorch.org.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import importlib.util\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "\n",
        "def pip_install(args):\n",
        "    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\"] + args, check=True)\n",
        "\n",
        "\n",
        "pip_install([\"-U\", \"pip\"])\n",
        "\n",
        "if importlib.util.find_spec(\"torch\") is None:\n",
        "    print(\"Installing torch/torchvision. For GPU builds, replace this line with the command from pytorch.org.\")\n",
        "    pip_install([\"torch\", \"torchvision\"])\n",
        "\n",
        "pip_install([\"-r\", str(REPO_DIR / \"requirements.txt\")])\n",
        "pip_install([\"matplotlib\", \"huggingface_hub\"])\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Download raw data\n",
        "Most datasets require agreeing to their terms. The helper below covers a few tasks and prints guidance for others.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import subprocess\n",
        "from pathlib import Path\n",
        "\n",
        "RAW_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "CACHE_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "RAW_READY = False\n",
        "DEEPMIMO_DIR = None\n",
        "POS_DIR = None\n",
        "\n",
        "if TASK.startswith(\"deepmimo\"):\n",
        "    DEEPMIMO_DIR = RAW_ROOT / \"deepmimo_scenarios\"\n",
        "    if DOWNLOAD_RAW and not DEEPMIMO_DIR.exists():\n",
        "        print(\"Cloning DeepMIMO scenarios via git-lfs (this can be large).\")\n",
        "        subprocess.run([\"git\", \"lfs\", \"install\"], check=False)\n",
        "        subprocess.run([\"git\", \"clone\", \"https://huggingface.co/datasets/wi-lab/lwm\", str(DEEPMIMO_DIR)], check=True)\n",
        "    RAW_READY = DEEPMIMO_DIR.exists()\n",
        "elif TASK == \"rml\":\n",
        "    RML_REPO = RAW_ROOT / \"RML22\"\n",
        "    if DOWNLOAD_RAW and not RML_REPO.exists():\n",
        "        subprocess.run([\"git\", \"clone\", \"https://github.com/venkateshsathya/RML22\", str(RML_REPO)], check=True)\n",
        "    RAW_READY = RML_DATA_FILE.exists()\n",
        "    if not RAW_READY:\n",
        "        print(\"RML data file not found at:\", RML_DATA_FILE)\n",
        "        print(\"Download RML22.01A (or RML2016.10a_dict.pkl) and set RML_DATA_FILE.\")\n",
        "elif TASK == \"pos\":\n",
        "    POS_DIR = RAW_ROOT / \"pos\"\n",
        "    RAW_READY = POS_DIR.exists()\n",
        "    if not RAW_READY:\n",
        "        print(\"Download the POS dataset from IEEE Dataport and place the .h5 files under:\", POS_DIR)\n",
        "else:\n",
        "    print(\"No download helper for task:\", TASK)\n",
        "    print(\"See dataset docs in the WavesFM site and update RAW_ROOT accordingly.\")\n",
        "\n",
        "print(\"Raw data ready:\", RAW_READY)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Preprocess raw data into a .h5 cache\n",
        "This converts raw files into a single cache that WavesFM can load quickly.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import sys\n",
        "import subprocess\n",
        "\n",
        "if not PREPROCESS:\n",
        "    print(\"Skipping preprocessing.\")\n",
        "elif CACHE_PATH.exists():\n",
        "    print(\"Using existing cache at:\", CACHE_PATH)\n",
        "else:\n",
        "    if TASK.startswith(\"deepmimo\"):\n",
        "        if not DEEPMIMO_DIR or not DEEPMIMO_DIR.exists():\n",
        "            raise FileNotFoundError(\"DeepMIMO scenarios not found. Run the download cell first.\")\n",
        "        cmd = [\n",
        "            sys.executable, str(REPO_DIR / \"preprocessing/preprocess_deepmimo.py\"),\n",
        "            \"--output\", str(CACHE_PATH),\n",
        "            \"--dataset-folder\", str(DEEPMIMO_DIR),\n",
        "            \"--scenario-idxs\", DEEP_MIMO_SCENARIO_IDXS,\n",
        "            \"--n-beams\", str(DEEP_MIMO_N_BEAMS),\n",
        "            \"--n-beams-list\", str(DEEP_MIMO_N_BEAMS),\n",
        "        ]\n",
        "        subprocess.run(cmd, check=True)\n",
        "    elif TASK == \"rml\":\n",
        "        if not RML_DATA_FILE.exists():\n",
        "            raise FileNotFoundError(f\"Missing RML data file at {RML_DATA_FILE}\")\n",
        "        cmd = [\n",
        "            sys.executable, str(REPO_DIR / \"preprocessing/preprocess_rml.py\"),\n",
        "            \"--data-file\", str(RML_DATA_FILE),\n",
        "            \"--version\", RML_VERSION,\n",
        "            \"--output\", str(CACHE_PATH),\n",
        "        ]\n",
        "        subprocess.run(cmd, check=True)\n",
        "    elif TASK == \"pos\":\n",
        "        POS_DIR = RAW_ROOT / \"pos\"\n",
        "        if not POS_DIR.exists():\n",
        "            raise FileNotFoundError(f\"Missing POS directory at {POS_DIR}\")\n",
        "        cmd = [\n",
        "            sys.executable, str(REPO_DIR / \"preprocessing/preprocess_nr_positioning.py\"),\n",
        "            \"--data-path\", str(POS_DIR),\n",
        "            \"--output\", str(CACHE_PATH),\n",
        "            \"--scene\", POS_SCENE,\n",
        "        ]\n",
        "        subprocess.run(cmd, check=True)\n",
        "    else:\n",
        "        raise ValueError(f\"No preprocessing recipe for task {TASK}\")\n",
        "\n",
        "print(\"Cache ready:\", CACHE_PATH.exists())\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Download a pretrained checkpoint\n",
        "WavesFM weights are hosted on Hugging Face. If you do not want to use a pretrained checkpoint, set `DOWNLOAD_PRETRAINED = False`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from pathlib import Path\n",
        "\n",
        "HF_REPO = \"ahmedaboulfo/wavesfm\"\n",
        "HF_FILE = None  # set to a specific checkpoint filename if you want to pin it\n",
        "\n",
        "PRETRAINED_PATH = None\n",
        "if DOWNLOAD_PRETRAINED:\n",
        "    from huggingface_hub import list_repo_files, hf_hub_download\n",
        "\n",
        "    CHECKPOINT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "    if HF_FILE is None:\n",
        "        files = [f for f in list_repo_files(HF_REPO) if f.endswith(\".pth\")]\n",
        "        if not files:\n",
        "            raise RuntimeError(\"No .pth checkpoints found in the Hugging Face repo.\")\n",
        "        HF_FILE = files[0]\n",
        "        print(\"Using checkpoint:\", HF_FILE)\n",
        "\n",
        "    PRETRAINED_PATH = Path(\n",
        "        hf_hub_download(repo_id=HF_REPO, filename=HF_FILE, local_dir=str(CHECKPOINT_DIR))\n",
        "    )\n",
        "    print(\"Downloaded to:\", PRETRAINED_PATH)\n",
        "else:\n",
        "    print(\"Skipping pretrained download.\")\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Finetune\n",
        "This runs the WavesFM CLI on your cache. Increase epochs and batch size for real training.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import sys\n",
        "import subprocess\n",
        "import torch\n",
        "\n",
        "if not CACHE_PATH.exists():\n",
        "    raise FileNotFoundError(f\"Missing cache at {CACHE_PATH}. Run preprocessing first.\")\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "train_cmd = [\n",
        "    sys.executable, str(REPO_DIR / \"main_finetune.py\"),\n",
        "    \"--task\", TASK,\n",
        "    \"--train-data\", str(CACHE_PATH),\n",
        "    \"--val-split\", str(VAL_SPLIT),\n",
        "    \"--output-dir\", str(OUTPUT_DIR),\n",
        "    \"--model\", MODEL_NAME,\n",
        "    \"--epochs\", str(EPOCHS),\n",
        "    \"--batch-size\", str(BATCH_SIZE),\n",
        "    \"--num-workers\", str(NUM_WORKERS),\n",
        "    \"--device\", device,\n",
        "]\n",
        "\n",
        "if USE_STRATIFIED_SPLIT:\n",
        "    train_cmd.append(\"--stratified-split\")\n",
        "if FULL_FINETUNE:\n",
        "    train_cmd.append(\"--sl-baseline\")\n",
        "if PRETRAINED_PATH:\n",
        "    train_cmd += [\"--finetune\", str(PRETRAINED_PATH)]\n",
        "if TASK == \"deepmimo-beam\":\n",
        "    train_cmd += [\"--deepmimo-n-beams\", str(DEEP_MIMO_N_BEAMS)]\n",
        "\n",
        "if RUN_TRAINING:\n",
        "    subprocess.run(train_cmd, check=True)\n",
        "else:\n",
        "    print(\"Skipping training. Command:\")\n",
        "    print(\" \".join(train_cmd))\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Evaluate and visualize\n",
        "Classification tasks produce a confusion matrix. Positioning tasks produce an error density plot.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from types import SimpleNamespace\n",
        "\n",
        "from data import build_datasets\n",
        "from main_finetune import build_model\n",
        "\n",
        "\n",
        "def get_base_dataset(ds):\n",
        "    base = ds\n",
        "    while hasattr(base, \"dataset\"):\n",
        "        base = base.dataset\n",
        "    return base\n",
        "\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "train_ds, val_ds, task_info = build_datasets(\n",
        "    TASK,\n",
        "    CACHE_PATH,\n",
        "    val_path=None,\n",
        "    val_split=VAL_SPLIT,\n",
        "    stratified_split=USE_STRATIFIED_SPLIT,\n",
        "    seed=42,\n",
        "    deepmimo_n_beams=DEEP_MIMO_N_BEAMS if TASK == \"deepmimo-beam\" else None,\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_ds,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    pin_memory=True,\n",
        ")\n",
        "\n",
        "args = SimpleNamespace(\n",
        "    model=MODEL_NAME,\n",
        "    global_pool=\"token\",\n",
        "    vis_img_size=224,\n",
        "    vis_patch=16,\n",
        "    iq_segment_len=16,\n",
        "    iq_downsample=None,\n",
        "    iq_target_len=256,\n",
        "    use_conditional_ln=False,\n",
        "    lora=False,\n",
        "    lora_rank=8,\n",
        "    lora_alpha=1.0,\n",
        ")\n",
        "\n",
        "model = build_model(args, task_info)\n",
        "\n",
        "ckpt_path = OUTPUT_DIR / \"best.pth\"\n",
        "if ckpt_path.exists():\n",
        "    ckpt = torch.load(ckpt_path, map_location=\"cpu\")\n",
        "    state = ckpt[\"model\"] if isinstance(ckpt, dict) and \"model\" in ckpt else ckpt\n",
        "    model.load_state_dict(state, strict=False)\n",
        "    print(\"Loaded finetuned checkpoint:\", ckpt_path)\n",
        "elif PRETRAINED_PATH:\n",
        "    ckpt = torch.load(PRETRAINED_PATH, map_location=\"cpu\")\n",
        "    state = ckpt[\"model\"] if isinstance(ckpt, dict) and \"model\" in ckpt else ckpt\n",
        "    model.load_state_dict(state, strict=False)\n",
        "    print(\"Loaded pretrained checkpoint:\", PRETRAINED_PATH)\n",
        "else:\n",
        "    print(\"No checkpoint found; evaluating random init.\")\n",
        "\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "if task_info.target_type == \"classification\":\n",
        "    num_classes = task_info.num_outputs\n",
        "    cm = np.zeros((num_classes, num_classes), dtype=np.int64)\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            samples, targets = batch[0], batch[1]\n",
        "            outputs = model(samples.to(device, non_blocking=True))\n",
        "            preds = outputs.argmax(dim=1).cpu().numpy()\n",
        "            t = targets.cpu().numpy().astype(int)\n",
        "            for ti, pi in zip(t, preds):\n",
        "                cm[ti, pi] += 1\n",
        "            correct += (preds == t).sum()\n",
        "            total += len(t)\n",
        "\n",
        "    acc = correct / max(1, total)\n",
        "    print(f\"Val accuracy: {acc:.4f}\")\n",
        "\n",
        "    labels = getattr(get_base_dataset(val_ds), \"labels\", None)\n",
        "\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(6, 6))\n",
        "    im = ax.imshow(cm, cmap=\"Blues\")\n",
        "    ax.set_title(\"Confusion matrix\")\n",
        "    ax.set_xlabel(\"Predicted\")\n",
        "    ax.set_ylabel(\"True\")\n",
        "\n",
        "    if labels and len(labels) == num_classes and num_classes <= 30:\n",
        "        ax.set_xticks(range(num_classes))\n",
        "        ax.set_yticks(range(num_classes))\n",
        "        ax.set_xticklabels(labels, rotation=90, fontsize=8)\n",
        "        ax.set_yticklabels(labels, fontsize=8)\n",
        "\n",
        "    fig.colorbar(im, ax=ax)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "elif task_info.target_type == \"position\":\n",
        "    coord_min = task_info.coord_min.to(device)\n",
        "    coord_max = task_info.coord_max.to(device)\n",
        "\n",
        "    def denorm(x):\n",
        "        return (x + 1) * 0.5 * (coord_max - coord_min) + coord_min\n",
        "\n",
        "    errors = []\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            samples, targets = batch[0], batch[1]\n",
        "            preds = model(samples.to(device, non_blocking=True))\n",
        "            pred_m = denorm(preds)\n",
        "            true_m = denorm(targets.to(device, non_blocking=True))\n",
        "            dist = torch.linalg.norm(pred_m - true_m, dim=-1)\n",
        "            errors.append(dist.cpu().numpy())\n",
        "\n",
        "    errors = np.concatenate(errors)\n",
        "    print(f\"Mean error (m): {errors.mean():.3f}\")\n",
        "    print(f\"Median error (m): {np.median(errors):.3f}\")\n",
        "\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    try:\n",
        "        from scipy.stats import gaussian_kde\n",
        "\n",
        "        x = np.linspace(0, np.percentile(errors, 99), 200)\n",
        "        kde = gaussian_kde(errors)\n",
        "        y = kde(x)\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=(6, 4))\n",
        "        ax.plot(x, y, label=\"KDE\")\n",
        "        ax.hist(errors, bins=40, density=True, alpha=0.3, label=\"Histogram\")\n",
        "        ax.set_xlabel(\"Positioning error (m)\")\n",
        "        ax.set_ylabel(\"Density\")\n",
        "        ax.set_title(\"Positioning error density\")\n",
        "        ax.legend()\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    except Exception as exc:\n",
        "        print(\"KDE failed:\", exc)\n",
        "        plt.hist(errors, bins=40, density=True)\n",
        "        plt.xlabel(\"Positioning error (m)\")\n",
        "        plt.ylabel(\"Density\")\n",
        "        plt.show()\n",
        "\n",
        "else:\n",
        "    errors = []\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            samples, targets = batch[0], batch[1]\n",
        "            preds = model(samples.to(device, non_blocking=True))\n",
        "            err = (preds.squeeze() - targets.to(device, non_blocking=True).squeeze()).abs()\n",
        "            errors.append(err.cpu().numpy())\n",
        "\n",
        "    errors = np.concatenate(errors)\n",
        "    print(f\"MAE: {errors.mean():.4f}\")\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next steps\n",
        "- Increase `EPOCHS` and `BATCH_SIZE` for real runs.\n",
        "- Swap `TASK` to other datasets and update the download/preprocess settings.\n",
        "- Use `OUTPUT_DIR` to track checkpoints and logs.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}