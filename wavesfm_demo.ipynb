{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "404ed1dd",
   "metadata": {},
   "source": [
    "### This demo runs much faster on a GPU runtime (e.g., Colab: Runtime \u2192 Change runtime type \u2192 GPU).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497f1390",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import subprocess\n",
    "import json\n",
    "import random\n",
    "import importlib.util\n",
    "import os\n",
    "import shlex\n",
    "\n",
    "# --- Colab-friendly helpers ---\n",
    "try:\n",
    "    from IPython import get_ipython\n",
    "except Exception:  # pragma: no cover - best effort\n",
    "    get_ipython = lambda: None\n",
    "\n",
    "\n",
    "def is_colab():\n",
    "    return (\n",
    "        \"google.colab\" in sys.modules\n",
    "        or \"COLAB_RELEASE_TAG\" in os.environ\n",
    "        or \"COLAB_GPU\" in os.environ\n",
    "    )\n",
    "\n",
    "\n",
    "def run_cmd(cmd, *, cwd=None, check=True):\n",
    "    if isinstance(cmd, (list, tuple)):\n",
    "        cmd_list = [str(c) for c in cmd]\n",
    "        cmd_str = \" \".join(shlex.quote(c) for c in cmd_list)\n",
    "    else:\n",
    "        cmd_list = None\n",
    "        cmd_str = str(cmd)\n",
    "\n",
    "    if is_colab():\n",
    "        ip = get_ipython()\n",
    "        if ip is not None:\n",
    "            status = ip.system(cmd_str)\n",
    "            if check and status not in (0, None):\n",
    "                raise RuntimeError(f\"Command failed with status {status}: {cmd_str}\")\n",
    "            return status\n",
    "\n",
    "    if cmd_list is None:\n",
    "        return subprocess.run(cmd_str, shell=True, check=check, cwd=cwd)\n",
    "    return subprocess.run(cmd_list, check=check, cwd=cwd)\n",
    "\n",
    "\n",
    "# --- clone repo if needed ---\n",
    "REPO_URL = \"https://github.com/AhmedTarek62/wavesfm\"\n",
    "if (Path.cwd() / \"main_finetune.py\").exists():\n",
    "    REPO_DIR = Path.cwd()\n",
    "else:\n",
    "    REPO_DIR = Path(\"/content/wavesfm\")\n",
    "    if not REPO_DIR.exists():\n",
    "        run_cmd([\"git\", \"clone\", REPO_URL, str(REPO_DIR)])\n",
    "    os.chdir(REPO_DIR)\n",
    "\n",
    "if str(REPO_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(REPO_DIR))\n",
    "\n",
    "# --- install missing deps (Colab) ---\n",
    "def _ensure_pkg(module, pip_name=None):\n",
    "    if importlib.util.find_spec(module) is None:\n",
    "        pkg = pip_name or module\n",
    "        run_cmd([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", pkg])\n",
    "\n",
    "if importlib.util.find_spec(\"torch\") is None:\n",
    "    run_cmd([\n",
    "        sys.executable, \"-m\", \"pip\", \"install\", \"-q\",\n",
    "        \"torch\", \"torchvision\", \"torchaudio\"\n",
    "    ])\n",
    "\n",
    "for mod, pip_name in [\n",
    "    (\"numpy\", \"numpy\"),\n",
    "    (\"matplotlib\", \"matplotlib\"),\n",
    "    (\"h5py\", \"h5py\"),\n",
    "    (\"scipy\", \"scipy\"),\n",
    "    (\"tqdm\", \"tqdm\"),\n",
    "    (\"timm\", \"timm\"),\n",
    "    (\"pandas\", \"pandas\"),\n",
    "    (\"PIL\", \"pillow\"),\n",
    "    (\"gdown\", \"gdown\"),\n",
    "    (\"DeepMIMOV3\", \"DeepMIMOV3\"),\n",
    "]:\n",
    "    _ensure_pkg(mod, pip_name)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import h5py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e265cf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "TASK = \"sensing\"  # {\"sensing\", \"deepmimo-los\", \"rml\", \"uwb-industrial\"}\n",
    "DOWNLOAD_DATA = True      # set False if you already downloaded the raw files\n",
    "SEED = 1\n",
    "VAL_SPLIT = 0.2\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "# Demo epochs (small by default; increase for better metrics)\n",
    "EPOCHS_BY_TASK = {\"rml\": 10, \"deepmimo-los\": 10, \"uwb-industrial\": 20,}\n",
    "DEFAULT_EPOCHS = 50\n",
    "BATCH_SIZE_BY_TASK = {\"rml\": 2048,}\n",
    "DEFAULT_BATCH = 256\n",
    "\n",
    "epochs = EPOCHS_BY_TASK.get(TASK, DEFAULT_EPOCHS)\n",
    "batch_size = BATCH_SIZE_BY_TASK.get(TASK, DEFAULT_BATCH)\n",
    "\n",
    "# Finetuning regime\n",
    "FINETUNE_MODE = \"ft2\"  # {\"lp\", \"ft2\", \"lora\"}\n",
    "FT2_FROZEN_BLOCKS = 6\n",
    "LORA_RANK = 32\n",
    "LORA_ALPHA = 64\n",
    "\n",
    "STRATIFIED_TASKS = {\"deepmimo-los\"}\n",
    "SMOOTH_TASKS = {\"sensing\": 0.1}\n",
    "\n",
    "# Paths\n",
    "DATA_ROOT = Path(\"data\")\n",
    "RAW_ROOT = DATA_ROOT / \"raw\"\n",
    "CACHE_ROOT = DATA_ROOT / \"cache\"\n",
    "OUTPUT_DIR = Path(\"runs/demo\") / TASK\n",
    "CHECKPOINT_DIR = Path(\"checkpoints\")\n",
    "\n",
    "for p in (RAW_ROOT, CACHE_ROOT, CHECKPOINT_DIR, OUTPUT_DIR):\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Raw dataset locations (after download/extraction)\n",
    "HAS_DIR = RAW_ROOT / \"NTU-Fi_HAR\"              # EfficientFi HAS (sensing)\n",
    "RML_DATA_FILE = RAW_ROOT / \"rml2022\"            # RML 2022 (rml)\n",
    "UWB_INDUSTRIAL_DATA_FILE = RAW_ROOT / \"industrial_training.pkl\"  # UWB Industrial (uwb-industrial)\n",
    "DEEPMIMO_SCENARIOS_DIR = RAW_ROOT / \"deepmimo_scenarios\"          # DeepMIMO scenarios clone target\n",
    "DEEPMIMO_IMG_SIZE = 32\n",
    "DEEPMIMO_CLONE = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7469ab72",
   "metadata": {},
   "source": [
    "**Demo note:** this notebook uses a *small* number of epochs by default for quick runs. Increase `DEFAULT_EPOCHS` / `EPOCHS_BY_TASK` for better metrics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da970122",
   "metadata": {},
   "source": [
    "## Helpers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e4f4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from types import SimpleNamespace\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "from data import build_datasets\n",
    "from main_finetune import build_model\n",
    "\n",
    "\n",
    "def _unwrap_subset_with_indices(ds):\n",
    "    if not isinstance(ds, Subset):\n",
    "        return ds, None\n",
    "    indices = list(ds.indices)\n",
    "    base = ds.dataset\n",
    "    while isinstance(base, Subset):\n",
    "        indices = [base.indices[i] for i in indices]\n",
    "        base = base.dataset\n",
    "    return base, np.asarray(indices, dtype=np.int64)\n",
    "\n",
    "\n",
    "def _load_label_names(ds, task_info):\n",
    "    base, _ = _unwrap_subset_with_indices(ds)\n",
    "    labels = getattr(base, \"labels\", None)\n",
    "    if labels:\n",
    "        return list(labels)\n",
    "    h5_path = getattr(base, \"h5_path\", None)\n",
    "    if h5_path:\n",
    "        with h5py.File(h5_path, \"r\") as h5:\n",
    "            raw = h5.attrs.get(\"labels\", None)\n",
    "            if raw:\n",
    "                return list(json.loads(raw))\n",
    "            raw = h5.attrs.get(\"labels_los\", None)\n",
    "            if raw:\n",
    "                return list(json.loads(raw))\n",
    "    return [str(i) for i in range(task_info.num_outputs)]\n",
    "\n",
    "\n",
    "def plot_samples(ds, task_info, *, seed=0, num_show=6, anchor_idx=0):\n",
    "    rng = random.Random(seed)\n",
    "    num_show = min(num_show, len(ds))\n",
    "    indices = rng.sample(range(len(ds)), num_show)\n",
    "\n",
    "    def _to_numpy(x):\n",
    "        if torch.is_tensor(x):\n",
    "            return x.detach().cpu().numpy()\n",
    "        return np.asarray(x)\n",
    "\n",
    "    def _label_text(label):\n",
    "        if torch.is_tensor(label):\n",
    "            label = label.detach().cpu().numpy()\n",
    "        label = np.asarray(label)\n",
    "        if label.shape == ():\n",
    "            return f\"label={int(label)}\"\n",
    "        return f\"label={np.array2string(label, precision=2, separator=',')}\"\n",
    "\n",
    "    def _plot_rml(ax, sample):\n",
    "        x = _to_numpy(sample)\n",
    "        if x.ndim == 3 and x.shape[1] == 1:\n",
    "            x = x[:, 0, :]\n",
    "        i = x[0]\n",
    "        q = x[1]\n",
    "        ax.plot(i, label=\"I\")\n",
    "        ax.plot(q, label=\"Q\")\n",
    "        ax.legend(fontsize=6)\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    def _plot_uwb(ax, sample):\n",
    "        x = _to_numpy(sample)\n",
    "        if x.ndim != 3 or x.shape[0] < 2:\n",
    "            ax.plot(x.flatten())\n",
    "            ax.axis(\"off\")\n",
    "            return\n",
    "        a = min(anchor_idx, x.shape[1] - 1)\n",
    "        i = x[0, a]\n",
    "        q = x[1, a]\n",
    "        ax.plot(i, label=\"I\")\n",
    "        ax.plot(q, label=\"Q\")\n",
    "        ax.legend(fontsize=6)\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    def _plot_deepmimo(ax, sample):\n",
    "        x = _to_numpy(sample)\n",
    "        real = x[0]\n",
    "        imag = x[1]\n",
    "        mag = np.abs(real + 1j * imag)\n",
    "        ax.imshow(mag, cmap=\"viridis\")\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    def _plot_sensing(ax, sample):\n",
    "        x = _to_numpy(sample)\n",
    "        if x.ndim == 3:\n",
    "            x = (x - x.min()) / (x.max() - x.min() + 1e-8)\n",
    "            img = np.moveaxis(x, 0, -1)\n",
    "            ax.imshow(img)\n",
    "            ax.axis(\"off\")\n",
    "        else:\n",
    "            ax.plot(x.flatten())\n",
    "            ax.axis(\"off\")\n",
    "\n",
    "    fig, axes = plt.subplots(1, num_show, figsize=(3 * num_show, 3))\n",
    "    if num_show == 1:\n",
    "        axes = [axes]\n",
    "    for ax, idx in zip(axes, indices):\n",
    "        batch = ds[idx]\n",
    "        if len(batch) == 2:\n",
    "            sample, label = batch\n",
    "        elif len(batch) == 3:\n",
    "            sample, label = batch[0:2]\n",
    "        else:\n",
    "            raise ValueError(\"Unexpected sample format from dataset\")\n",
    "        if TASK == \"rml\":\n",
    "            _plot_rml(ax, sample)\n",
    "        elif TASK == \"uwb-industrial\":\n",
    "            _plot_uwb(ax, sample)\n",
    "        elif TASK == \"deepmimo-los\":\n",
    "            _plot_deepmimo(ax, sample)\n",
    "        elif TASK == \"sensing\":\n",
    "            _plot_sensing(ax, sample)\n",
    "        else:\n",
    "            ax.plot(_to_numpy(sample).flatten())\n",
    "            ax.axis(\"off\")\n",
    "        ax.set_title(_label_text(label))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def pick_eval_ckpt(output_dir: Path) -> Path:\n",
    "    best = output_dir / \"best.pth\"\n",
    "    if best.exists():\n",
    "        return best\n",
    "    candidates = list(output_dir.glob(\"checkpoint_*.pth\"))\n",
    "    if candidates:\n",
    "        def _ckpt_epoch(path: Path) -> int:\n",
    "            match = re.search(r\"checkpoint_(\\d+)\\.pth\", path.name)\n",
    "            return int(match.group(1)) if match else -1\n",
    "        return max(candidates, key=_ckpt_epoch)\n",
    "    raise FileNotFoundError(f\"No checkpoints found in {output_dir}\")\n",
    "\n",
    "\n",
    "def load_eval_model(ckpt_path: Path, task_info, *, device: str = \"cpu\"):\n",
    "    model_args = SimpleNamespace(\n",
    "        model=\"vit_multi_small\",\n",
    "        global_pool=\"token\",\n",
    "        vis_patch=16,\n",
    "        vis_img_size=DEEPMIMO_IMG_SIZE if TASK.startswith(\"deepmimo\") else 224,\n",
    "        iq_segment_len=16,\n",
    "        iq_downsample=None,\n",
    "        iq_target_len=256,\n",
    "        use_conditional_ln=True,\n",
    "    )\n",
    "    model = build_model(model_args, task_info)\n",
    "    ckpt = torch.load(ckpt_path, map_location=\"cpu\", weights_only=False)\n",
    "    state = ckpt.get(\"model\", ckpt) if isinstance(ckpt, dict) else ckpt\n",
    "    model.load_state_dict(state, strict=False)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(model, val_ds, task_info, *, batch_size=256, device=\"cpu\", annotate=True):\n",
    "    loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "    num_classes = task_info.num_outputs\n",
    "    conf = np.zeros((num_classes, num_classes), dtype=int)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            samples, targets = batch[0].to(device), batch[1].to(device).long()\n",
    "            outputs = model(samples)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            for t, p in zip(targets.cpu().numpy(), preds.cpu().numpy()):\n",
    "                conf[int(t), int(p)] += 1\n",
    "\n",
    "    with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "        row_sums = conf.sum(axis=1, keepdims=True)\n",
    "        conf_norm = np.divide(conf, row_sums, out=np.zeros_like(conf, dtype=float), where=row_sums != 0)\n",
    "\n",
    "    label_names = _load_label_names(val_ds, task_info)\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    im = ax.imshow(conf_norm, cmap=\"Blues\", vmin=0.0, vmax=1.0)\n",
    "    ax.set_title(f\"Confusion Matrix ({TASK})\")\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"True\")\n",
    "    ax.set_xticks(range(num_classes))\n",
    "    ax.set_yticks(range(num_classes))\n",
    "    ax.set_xticklabels(label_names, rotation=45, ha=\"right\")\n",
    "    ax.set_yticklabels(label_names)\n",
    "\n",
    "    if annotate:\n",
    "        for i in range(num_classes):\n",
    "            for j in range(num_classes):\n",
    "                val = conf_norm[i, j]\n",
    "                ax.text(j, i, f\"{val:.2f}\", ha=\"center\", va=\"center\", color=\"black\", fontsize=8)\n",
    "\n",
    "    fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_position_error_pdf(model, val_ds, *, batch_size=256, device=\"cpu\", bins=60):\n",
    "    base, _ = _unwrap_subset_with_indices(val_ds)\n",
    "    if not hasattr(base, \"loc_min\") or not hasattr(base, \"loc_max\"):\n",
    "        print(\"UWB location metadata missing; skipping error PDF plot.\")\n",
    "        return\n",
    "\n",
    "    coord_min = base.loc_min.to(device)\n",
    "    coord_max = base.loc_max.to(device)\n",
    "\n",
    "    def _denorm(x):\n",
    "        return (x + 1) * 0.5 * (coord_max - coord_min) + coord_min\n",
    "\n",
    "    loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=NUM_WORKERS)\n",
    "    errors = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            samples, targets = batch[0].to(device), batch[1].to(device)\n",
    "            outputs = model(samples)\n",
    "            pred = _denorm(outputs)\n",
    "            true = _denorm(targets)\n",
    "            dist = torch.linalg.norm(pred - true, dim=-1)\n",
    "            errors.append(dist.detach().cpu().numpy())\n",
    "\n",
    "    if not errors:\n",
    "        print(\"No samples available for error PDF plot.\")\n",
    "        return\n",
    "\n",
    "    errors = np.concatenate(errors, axis=0).astype(np.float64)\n",
    "    n = int(errors.size)\n",
    "    max_bins = max(20, int(np.sqrt(n)))\n",
    "    effective_bins = min(bins, max_bins)\n",
    "    hist, edges = np.histogram(errors, bins=effective_bins, density=True)\n",
    "    centers = 0.5 * (edges[:-1] + edges[1:])\n",
    "    mean = float(errors.mean())\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6, 4))\n",
    "    ax.plot(centers, hist, color=\"#1f77b4\", linewidth=2)\n",
    "    ax.fill_between(centers, hist, color=\"#1f77b4\", alpha=0.25)\n",
    "    ax.axvline(mean, color=\"#d62728\", linestyle=\"--\", linewidth=1.5)\n",
    "    ax.text(\n",
    "        0.98,\n",
    "        0.95,\n",
    "        f\"mean={mean:.2f}\",\n",
    "        transform=ax.transAxes,\n",
    "        ha=\"right\",\n",
    "        va=\"top\",\n",
    "        fontsize=9,\n",
    "        color=\"#d62728\",\n",
    "    )\n",
    "    ax.set_xlabel(\"Position error distance\")\n",
    "    ax.set_ylabel(\"Density\")\n",
    "    ax.grid(True, alpha=0.2)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_rml_accuracy_vs_snr(model, val_ds, *, batch_size=256, device=\"cpu\"):\n",
    "    base, idxs = _unwrap_subset_with_indices(val_ds)\n",
    "    snr_by_index = getattr(base, \"snr_by_index\", None)\n",
    "    if snr_by_index is None:\n",
    "        print(\"SNR metadata not found; skipping accuracy vs SNR plot.\")\n",
    "        return\n",
    "\n",
    "    snrs = np.asarray(snr_by_index, dtype=np.int16)\n",
    "    if idxs is not None:\n",
    "        snrs = snrs[idxs]\n",
    "\n",
    "    loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "    offset = 0\n",
    "    correct = {}\n",
    "    total = {}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            samples, targets = batch[0].to(device), batch[1].to(device).long()\n",
    "            outputs = model(samples)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            batch_snrs = snrs[offset: offset + len(targets)]\n",
    "            offset += len(targets)\n",
    "\n",
    "            for snr_val, p, t in zip(batch_snrs, preds.cpu().numpy(), targets.cpu().numpy()):\n",
    "                snr_val = int(snr_val)\n",
    "                total[snr_val] = total.get(snr_val, 0) + 1\n",
    "                correct[snr_val] = correct.get(snr_val, 0) + int(p == t)\n",
    "\n",
    "    snr_levels = sorted(total.keys())\n",
    "    acc = [correct[s] / total[s] for s in snr_levels]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6, 4))\n",
    "    ax.plot(snr_levels, acc, marker=\"o\")\n",
    "    ax.set_title(\"RML Accuracy vs SNR\")\n",
    "    ax.set_xlabel(\"SNR\")\n",
    "    ax.set_ylabel(\"Accuracy\")\n",
    "    ax.set_ylim(0.0, 1.0)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd68d85",
   "metadata": {},
   "source": [
    "## Download raw datasets\n",
    "\n",
    "This notebook supports a **subset of tasks** only. For deeper experiments (more tasks, configs, and training options), refer to the full repository: https://github.com/AhmedTarek62/wavesfm\n",
    "\n",
    "### Vision tasks\n",
    "- `sensing` \u2014 EfficientFi (Human Activity Sensing): https://github.com/xyanchen/WiFi-CSI-Sensing-Benchmark  \n",
    "- `deepmimo-los` \u2014 DeepMIMO LoS/NLoS classification (generated locally via `preprocess_deepmimo.py`; no manual downloads)\n",
    "\n",
    "### IQ tasks\n",
    "- `rml` \u2014 RML 2022 (Modulation Classification): https://github.com/venkateshsathya/RML22  \n",
    "- `uwb-industrial` \u2014 UWB Industrial Positioning: https://owncloud.fraunhofer.de/index.php/s/AXFjGY9IhswfBSa/download\n",
    "\n",
    "#\n",
    "> **Note:** Links were valid at the time this notebook was published. If a link breaks, please use the corresponding project page above to locate the latest download instructions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa912dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional dataset download\n",
    "\n",
    "if not DOWNLOAD_DATA:\n",
    "    print(\"DOWNLOAD_DATA=False \u2192 assuming raw files already exist under:\", RAW_ROOT)\n",
    "\n",
    "elif TASK == \"sensing\":\n",
    "    # EfficientFi HAS (Google Drive zip)\n",
    "    HAS_URL = \"https://drive.google.com/file/d/1DszE7byFzlpyI9gZvmVn51fTr8L1iZaI/view?usp=drive_link\"\n",
    "    zip_path = RAW_ROOT / \"has.zip\"\n",
    "    run_cmd([\"gdown\", \"--fuzzy\", \"-O\", str(zip_path), HAS_URL])\n",
    "    run_cmd([\"unzip\", \"-o\", str(zip_path), \"-d\", str(RAW_ROOT)])\n",
    "    run_cmd([\"rm\", str(zip_path)])\n",
    "\n",
    "elif TASK == \"deepmimo-los\":\n",
    "    print(\"DeepMIMO is generated during preprocessing; no download step needed.\")\n",
    "\n",
    "elif TASK == \"rml\":\n",
    "    # RML 2022 (Google Drive)\n",
    "    RML_URL = \"https://drive.google.com/file/d/1wrqnanHbmdFiP3DqaBjSVcBxoQ0nzD-a/view?usp=drive_link\"\n",
    "    out_path = RAW_ROOT / \"rml2022\"  # keep as downloaded filename; downstream code can point to it\n",
    "    run_cmd([\"gdown\", \"--fuzzy\", \"-O\", str(out_path), RML_URL])\n",
    "\n",
    "elif TASK == \"uwb-industrial\":\n",
    "    # UWB Industrial Positioning (Fraunhofer ownCloud)\n",
    "    UWB_URL = \"https://owncloud.fraunhofer.de/index.php/s/AXFjGY9IhswfBSa/download\"\n",
    "    pkl_path = UWB_INDUSTRIAL_DATA_FILE\n",
    "    run_cmd([\"wget\", \"-O\", str(pkl_path), UWB_URL])\n",
    "\n",
    "else:\n",
    "    raise ValueError(f\"Unknown TASK={TASK!r}. Expected one of: sensing, deepmimo-los, rml, uwb-industrial.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40606f7",
   "metadata": {},
   "source": [
    "## Create preprocessed .h5 cache from raw data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d20f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- cache path ---\n",
    "if TASK == \"sensing\":\n",
    "    CACHE_PATH = CACHE_ROOT / \"has.h5\"\n",
    "elif TASK == \"deepmimo-los\":\n",
    "    CACHE_PATH = CACHE_ROOT / \"deepmimo.h5\"\n",
    "elif TASK == \"rml\":\n",
    "    CACHE_PATH = CACHE_ROOT / \"rml2022.h5\"\n",
    "elif TASK == \"uwb-industrial\":\n",
    "    CACHE_PATH = CACHE_ROOT / \"uwb-industrial.h5\"\n",
    "else:\n",
    "    raise ValueError(f\"Unsupported TASK: {TASK}\")\n",
    "\n",
    "print(\"Task:\", TASK)\n",
    "print(\"Cache path:\", CACHE_PATH)\n",
    "\n",
    "# --- preprocess (skip this cell if you already have CACHE_PATH) ---\n",
    "if TASK == \"sensing\":\n",
    "    run_cmd([\n",
    "        sys.executable, \"preprocessing/preprocess_csi_sensing.py\",\n",
    "        \"--data-path\", str(HAS_DIR),\n",
    "        \"--output\", str(CACHE_PATH),\n",
    "        \"--overwrite\"], check=True)\n",
    "\n",
    "elif TASK == \"deepmimo-los\":\n",
    "    deepmimo_cmd = [\n",
    "        sys.executable, \"preprocessing/preprocess_deepmimo.py\",\n",
    "        \"--output\", str(CACHE_PATH),\n",
    "        \"--dataset-folder\", str(DEEPMIMO_SCENARIOS_DIR),\n",
    "        \"--resize-size\", str(DEEPMIMO_IMG_SIZE),\n",
    "        \"--overwrite\",\n",
    "    ]\n",
    "    if DEEPMIMO_CLONE:\n",
    "        deepmimo_cmd.append(\"--clone-scenarios\")\n",
    "    run_cmd(deepmimo_cmd, check=True)\n",
    "\n",
    "elif TASK == \"rml\":\n",
    "    if not RML_DATA_FILE.exists():\n",
    "        raise FileNotFoundError(f\"Missing RML file at {RML_DATA_FILE}\")\n",
    "    run_cmd([\n",
    "        sys.executable, \"preprocessing/preprocess_rml.py\",\n",
    "        \"--data-file\", str(RML_DATA_FILE),\n",
    "        \"--version\", \"2022\",\n",
    "        \"--output\", str(CACHE_PATH),\n",
    "        \"--overwrite\",\n",
    "    ], check=True)\n",
    "\n",
    "elif TASK == \"uwb-industrial\":\n",
    "    if not UWB_INDUSTRIAL_DATA_FILE.exists():\n",
    "        raise FileNotFoundError(f\"Missing UWB-Industrial file at {UWB_INDUSTRIAL_DATA_FILE}\")\n",
    "    run_cmd([\n",
    "        sys.executable, \"preprocessing/preprocess_ipin_loc.py\",\n",
    "        \"--data-path\", str(UWB_INDUSTRIAL_DATA_FILE),\n",
    "        \"--output\", str(CACHE_PATH),\n",
    "        \"--overwrite\",\n",
    "    ], check=True)\n",
    "\n",
    "TRAIN_CACHE_PATH = CACHE_PATH\n",
    "print(\"Train cache path:\", TRAIN_CACHE_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6383161c",
   "metadata": {},
   "source": [
    "## Visualize cached samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff484bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, val_ds, task_info = build_datasets(\n",
    "    TASK,\n",
    "    str(TRAIN_CACHE_PATH),\n",
    "    val_path=None,\n",
    "    val_split=VAL_SPLIT,\n",
    "    stratified_split=TASK in STRATIFIED_TASKS,\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "plot_samples(train_ds, task_info, seed=SEED)\n",
    "print(\"Task info:\", task_info.modality)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf31f2f",
   "metadata": {},
   "source": [
    "## Download pretrained checkpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf357d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hub import download_pretrained\n",
    "\n",
    "HF_REPO = \"ahmedaboulfo/wavesfm\"\n",
    "HF_FILE = \"wavesfm-v1p0.pth\"\n",
    "\n",
    "PRETRAINED_PATH = Path(\n",
    "    download_pretrained(repo_id=HF_REPO, filename=HF_FILE, cache_dir=str(CHECKPOINT_DIR))\n",
    ")\n",
    "print(\"Downloaded to:\", PRETRAINED_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235d715d",
   "metadata": {},
   "source": [
    "## Finetune\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82099399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- finetune (match run_finetune_all.py defaults, seed 0) ---\n",
    "train_cmd = [\n",
    "    sys.executable, \"main_finetune.py\",\n",
    "    \"--task\", TASK,\n",
    "    \"--train-data\", str(TRAIN_CACHE_PATH),\n",
    "    \"--output-dir\", str(OUTPUT_DIR),\n",
    "    \"--batch-size\", str(batch_size),\n",
    "    \"--num-workers\", str(NUM_WORKERS),\n",
    "    \"--epochs\", str(epochs),\n",
    "    \"--seed\", str(SEED),\n",
    "    \"--val-split\", str(VAL_SPLIT),\n",
    "    \"--model\", \"vit_multi_small\",\n",
    "    \"--warmup-epochs\", \"5\",\n",
    "    \"--use-conditional-ln\",\n",
    "    \"--finetune\", str(PRETRAINED_PATH),\n",
    "]\n",
    "\n",
    "if FINETUNE_MODE == \"lora\":\n",
    "    train_cmd += [\"--lora\", \"--lora-rank\", str(LORA_RANK), \"--lora-alpha\", str(LORA_ALPHA)]\n",
    "elif FINETUNE_MODE == \"ft2\":\n",
    "    train_cmd += [\"--frozen-blocks\", str(FT2_FROZEN_BLOCKS)]\n",
    "elif FINETUNE_MODE != \"lp\":\n",
    "    raise ValueError(f\"Unknown FINETUNE_MODE={FINETUNE_MODE!r}. Expected lp/ft2/lora.\")\n",
    "\n",
    "if TASK in STRATIFIED_TASKS:\n",
    "    train_cmd += [\"--stratified-split\", \"--class-weights\"]\n",
    "if TASK in SMOOTH_TASKS:\n",
    "    train_cmd += [\"--smoothing\", str(SMOOTH_TASKS[TASK])]\n",
    "if TASK.startswith(\"deepmimo\"):\n",
    "    train_cmd += [\"--vis-img-size\", str(DEEPMIMO_IMG_SIZE)]\n",
    "\n",
    "run_cmd(train_cmd, check=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34674876",
   "metadata": {},
   "source": [
    "## Load evaluation checkpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ckpt = pick_eval_ckpt(OUTPUT_DIR)\n",
    "print(f\"Eval checkpoint: {best_ckpt}\")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "train_ds, val_ds, task_info = build_datasets(\n",
    "    TASK,\n",
    "    str(TRAIN_CACHE_PATH),\n",
    "    val_path=None,\n",
    "    val_split=VAL_SPLIT,\n",
    "    stratified_split=TASK in STRATIFIED_TASKS,\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "eval_model = load_eval_model(best_ckpt, task_info, device=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547c36b5",
   "metadata": {},
   "source": [
    "## Evaluation & plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33e8944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- eval-only metrics ---\n",
    "print(f\"Demo run: {epochs} epochs (mode: {FINETUNE_MODE}). Metrics are indicative.\")\n",
    "\n",
    "eval_cmd = [\n",
    "    sys.executable, \"main_finetune.py\",\n",
    "    \"--task\", TASK,\n",
    "    \"--train-data\", str(TRAIN_CACHE_PATH),\n",
    "    \"--batch-size\", str(batch_size),\n",
    "    \"--num-workers\", str(NUM_WORKERS),\n",
    "    \"--seed\", str(SEED),\n",
    "    \"--val-split\", str(VAL_SPLIT),\n",
    "    \"--model\", \"vit_multi_small\",\n",
    "    \"--warmup-epochs\", \"5\",\n",
    "    \"--use-conditional-ln\",\n",
    "    \"--eval-only\",\n",
    "    \"--finetune\", str(best_ckpt),\n",
    "]\n",
    "\n",
    "if TASK in STRATIFIED_TASKS:\n",
    "    eval_cmd += [\"--stratified-split\", \"--class-weights\"]\n",
    "if TASK in SMOOTH_TASKS:\n",
    "    eval_cmd += [\"--smoothing\", str(SMOOTH_TASKS[TASK])]\n",
    "if TASK.startswith(\"deepmimo\"):\n",
    "    eval_cmd += [\"--vis-img-size\", str(DEEPMIMO_IMG_SIZE)]\n",
    "\n",
    "run_cmd(eval_cmd, check=True)\n",
    "\n",
    "# --- plots ---\n",
    "if task_info.target_type == \"classification\":\n",
    "    plot_confusion_matrix(eval_model, val_ds, task_info, batch_size=batch_size, device=device, annotate=(TASK != \"rml\"))\n",
    "\n",
    "if TASK == \"uwb-industrial\":\n",
    "    plot_position_error_pdf(eval_model, val_ds, batch_size=batch_size, device=device)\n",
    "\n",
    "if TASK == \"rml\":\n",
    "    plot_rml_accuracy_vs_snr(eval_model, val_ds, batch_size=batch_size, device=device)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}